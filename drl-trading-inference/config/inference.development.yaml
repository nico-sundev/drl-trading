# Inference Service Configuration - Development Environment
# This file contains configuration for the inference service in development mode.

# Base Application Information
app_name: "drl-trading-inference"
version: "1.0.0"
deployment_mode: "development"

# Infrastructure Configuration
infrastructure:
  service_name: "drl-trading-inference"
  deployment_mode: "development"

  # Logging Configuration
  logging:
    level: "INFO"
    file_path: "logs/inference.log"
    console_enabled: true

  # Message Bus Configuration
  message_bus:
    provider: "in_memory"  # Use in_memory for development, rabbitmq for production
    connection_retry_attempts: 3

  # Monitoring Configuration
  monitoring:
    prometheus_enabled: false
    health_check_enabled: true
    health_check_port: 8081

# Model Configuration
model_config:
  model_path: "experiments/models/latest"
  model_format: "pickle"  # pickle, onnx, joblib
  batch_size: 1
  prediction_timeout: 5.0  # seconds

# Real-time Processing Configuration
processing_config:
  feature_buffer_size: 1000
  prediction_frequency: "1s"  # How often to generate predictions
  symbols: ["EURUSD"]  # Only symbols this service handles
  timeframes: ["H1"]   # Only timeframes needed for inference

  # Feature computation parameters
  feature_computation:
    incremental: true  # Use incremental feature computation
    context_window: 100  # Number of bars to keep in context
    use_feature_store: false  # Don't use feature store for inference

# Message Bus Routing Configuration
message_routing:
  input_topic: "market_data"
  output_topic: "trading_signals"
  error_topic: "inference_errors"
